# Set 1: Decrease lr parameter by a factor of 10
start "" python mod.py --lr 0.01 --weight_decay 2e-03 --gamma 0.9 --momentum 0.9 --num_steps 8 --batch 150 --epochs 300 --encoder_pth "encoder.pth" --classifier_pth "mod_classifier[1][1].pth" --loss_plot "loss.mod[1][1].png" --accuracy_plt "accuracy.mod[1][1].png" --training "a"
start "" python mod.py --lr 0.001 --weight_decay 2e-03 --gamma 0.9 --momentum 0.9 --num_steps 8 --batch 150 --epochs 300 --encoder_pth "encoder.pth" --classifier_pth "mod_classifier[1][2].pth" --loss_plot "loss.mod[1][2].png" --accuracy_plt "accuracy.mod[1][2].png" --training "a"
start "" python mod.py --lr 0.0001 --weight_decay 2e-03 --gamma 0.9 --momentum 0.9 --num_steps 8 --batch 150 --epochs 300 --encoder_pth "encoder.pth" --classifier_pth "mod_classifier[1][3].pth" --loss_plot "loss.mod[1][3].png" --accuracy_plt "accuracy.mod[1][3].png" --training "a"
start "" python mod.py --lr 0.00001 --weight_decay 2e-03 --gamma 0.9 --momentum 0.9 --num_steps 8 --batch 150 --epochs 300 --encoder_pth "encoder.pth" --classifier_pth "mod_classifier[1][4].pth" --loss_plot "loss.mod[1][4].png" --accuracy_plt "accuracy.mod[1][4].png" --training "a"

# Set 2: Reduce weight_decay by a factor of 10
start "" python mod.py --lr 0.1 --weight_decay 2e-04 --gamma 0.9 --momentum 0.9 --num_steps 8 --batch 150 --epochs 300 --encoder_pth "encoder.pth" --classifier_pth "mod_classifier[2][1].pth" --loss_plot "loss.mod[2][1].png" --accuracy_plt "accuracy.mod[2][1].png" --training "a"
start "" python mod.py --lr 0.1 --weight_decay 2e-05 --gamma 0.9 --momentum 0.9 --num_steps 8 --batch 150 --epochs 300 --encoder_pth "encoder.pth" --classifier_pth "mod_classifier[2][2].pth" --loss_plot "loss.mod[2][2].png" --accuracy_plt "accuracy.mod[2][2].png" --training "a"
start "" python mod.py --lr 0.1 --weight_decay 2e-06 --gamma 0.9 --momentum 0.9 --num_steps 8 --batch 150 --epochs 300 --encoder_pth "encoder.pth" --classifier_pth "mod_classifier[2][3].pth" --loss_plot "loss.mod[2][3].png" --accuracy_plt "accuracy.mod[2][3].png" --training "a"
start "" python mod.py --lr 0.1 --weight_decay 2e-07 --gamma 0.9 --momentum 0.9 --num_steps 8 --batch 150 --epochs 300 --encoder_pth "encoder.pth" --classifier_pth "mod_classifier[2][4].pth" --loss_plot "loss.mod[2][4].png" --accuracy_plt "accuracy.mod[2][4].png" --training "a"

# Set 3: Reduce gamma by 0.1
start "" python mod.py --lr 0.1 --weight_decay 2e-03 --gamma 0.8 --momentum 0.9 --num_steps 8 --batch 150 --epochs 300 --encoder_pth "encoder.pth" --classifier_pth "mod_classifier[3][1].pth" --loss_plot "loss.mod[3][1].png" --accuracy_plt "accuracy.mod[3][1].png" --training "a"
start "" python mod.py --lr 0.1 --weight_decay 2e-03 --gamma 0.7 --momentum 0.9 --num_steps 8 --batch 150 --epochs 300 --encoder_pth "encoder.pth" --classifier_pth "mod_classifier[3][2].pth" --loss_plot "loss.mod[3][2].png" --accuracy_plt "accuracy.mod[3][2].png" --training "a"
start "" python mod.py --lr 0.1 --weight_decay 2e-03 --gamma 0.6 --momentum 0.9 --num_steps 8 --batch 150 --epochs 300 --encoder_pth "encoder.pth" --classifier_pth "mod_classifier[3][3].pth" --loss_plot "loss.mod[3][3].png" --accuracy_plt "accuracy.mod[3][3].png" --training "a"
start "" python mod.py --lr 0.1 --weight_decay 2e-03 --gamma 0.5 --momentum 0.9 --num_steps 8 --batch 150 --epochs 300 --encoder_pth "encoder.pth" --classifier_pth "mod_classifier[3][4].pth" --loss_plot "loss.mod[3][4].png" --accuracy_plt "accuracy.mod[3][4].png" --training "a"

# Set 4: Reduce num_steps by 1
start "" python mod.py --lr 0.1 --weight_decay 2e-03 --gamma 0.9 --momentum 0.9 --num_steps 7 --batch 150 --epochs 300 --encoder_pth "encoder.pth" --classifier_pth "mod_classifier[4][1].pth" --loss_plot "loss.mod[4][1].png" --accuracy_plt "accuracy.mod[4][1].png" --training "a"
start "" python mod.py --lr 0.1 --weight_decay 2e-03 --gamma 0.9 --momentum 0.9 --num_steps 6 --batch 150 --epochs 300 --encoder_pth "encoder.pth" --classifier_pth "mod_classifier[4][2].pth" --loss_plot "loss.mod[4][2].png" --accuracy_plt "accuracy.mod[4][2].png" --training "a"
start "" python mod.py --lr 0.1 --weight_decay 2e-03 --gamma 0.9 --momentum 0.9 --num_steps 5 --batch 150 --epochs 300 --encoder_pth "encoder.pth" --classifier_pth "mod_classifier[4][3].pth" --loss_plot "loss.mod[4][3].png" --accuracy_plt "accuracy.mod[4][3].png" --training "a"
start "" python mod.py --lr 0.1 --weight_decay 2e-03 --gamma 0.9 --momentum 0.9 --num_steps 4 --batch 150 --epochs 300 --encoder_pth "encoder.pth" --classifier_pth "mod_classifier[4][4].pth" --loss_plot "loss.mod[4][4].png" --accuracy_plt "accuracy.mod[4][4].png" --training "a"

# Set 5: Reduce momentum by 0.1
start "" python mod.py --lr 0.1 --weight_decay 2e-03 --gamma 0.9 --momentum 0.8 --num_steps 8 --batch 150 --epochs 300 --encoder_pth "encoder.pth" --classifier_pth "mod_classifier[5][1].pth" --loss_plot "loss.mod[5][1].png" --accuracy_plt "accuracy.mod[5][1].png" --training "a"
start "" python mod.py --lr 0.1 --weight_decay 2e-03 --gamma 0.9 --momentum 0.7 --num_steps 8 --batch 150 --epochs 300 --encoder_pth "encoder.pth" --classifier_pth "mod_classifier[5][2].pth" --loss_plot "loss.mod[5][2].png" --accuracy_plt "accuracy.mod[5][2].png" --training "a"
start "" python mod.py --lr 0.1 --weight_decay 2e-03 --gamma 0.9 --momentum 0.6 --num_steps 8 --batch 150 --epochs 300 --encoder_pth "encoder.pth" --classifier_pth "mod_classifier[5][3].pth" --loss_plot "loss.mod[5][3].png" --accuracy_plt "accuracy.mod[5][3].png" --training "a"
start "" python mod.py --lr 0.1 --weight_decay 2e-03 --gamma 0.9 --momentum 0.5 --num_steps 8 --batch 150 --epochs 300 --encoder_pth "encoder.pth" --classifier_pth "mod_classifier[5][4].pth" --loss_plot "loss.mod[5][4].png" --accuracy_plt "accuracy.mod[5][4].png" --training "a"
